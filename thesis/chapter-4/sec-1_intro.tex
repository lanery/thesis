\section{Introduction}
\label{sec:4.1_intro}


% Motivate from EM perspective
% bio-insight from EM is hard
% CLEM has been developed to assist

Electron microscopy (EM) has transformed the way in which biologists understand intra- and inter-cellular systems. Due to the lack of inherent biological specificity, however, interpretation of EM datasets typically requires tedious expert analysis and annotation. For this reason, fluorescence microscopy (FM) is often used in conjunction with EM, complementing structural data with targeted biological labels. Fluorescent labelling, however, comes with several drawbacks. Sample preparation protocols are often laborious, time-consuming, and potentially damaging to the sample. Protocols must also be adapted to limit concentrations of heavy metal staining if intermediate processing of the sample is to be avoided \cite{kuipers2015scanning,lane2021optimization}. Fluorescent labelling is also susceptible to bleedthrough when multiple fluorophores are expressed in a single sample as well as varying specificity---Hoechst dyes, for instance, bind to both DNA and RNA. Furthermore, registering the separate imaging modalities across large spatial extents remains a technically challenging and primarily manual task \cite{russell20173d} [other references]. Correlative fluorescence and electron microscopy experiments are therefore typically limited in scope to the micron or tens of microns scale, and thus so are the regions for which biological labels can be provided \cite{russell20173d} [other references].

As recognition of organelles and other subcellular structures remains a pivotal obstacle in biological EM, we questioned whether large-scale EM datasets could be supplemented with biological labels through alternate means. To address this question, we sought to leverage recent advances in deep learning. Deep convolutional neural networks (CNN) in particular have been shown to be capable of inferring complex, non-linear relationships from image data \cite{he2016deep,januszewski2018high}. Prior work involving deep CNNs in the context of electron microscopy data has primarily been limited to applications in segmentation, denoising, and compressed sensing \cite{ede2021deep}. Semantic segmentation, the classification of pixels into discrete categories, does ultimately serve the purpose of adding biological labels to EM data. However, modern deep learning approaches require hours of tedious expert segmentation \cite{huang2014identifying,heinrich2018synaptic,liu2020automatic,spiers2021deep}. In order for \textcite{heinrich2020automatic} to amass sufficient training data for organelle segmentation, it required one person two weeks of manual segmentation per \SI{1}{\micro\meter^3} volume of image data; 28 blocks of this size were manually annotated in total to enable whole cell organelle segmentation.

Although relatively little attention has been paid to alternative applications in deep learning for EM data, recent work has focused on generating biological labels from other imaging modalities. \textcite{christiansen2018silico} designed a deep neural network to predict fluorescence labels from transmitted light images. \textcite{ounkomol2018label} extended the technique to generate 3D fluorescence from stacks of transmitted light microscopy data and further demonstrated the possibility of predicting immunofluorescence from EM images in order to facilitate automatic registration of fluorescence data with EM. To address the challenge of adding biological specificity to large-scale EM datasets, we thus explored the potential for a CNN to make label-free fluorescence predictions from electron microscopy image data.

In this work we present a deep CNN developed for generating fluorescence predictions on large-scale EM data of tissue and cellular samples. We demonstrate the performance of our model on thin sections of rat pancreas tissue, which have been immunolabelled with Alexa Fluor 594 and given a Hoechst counterstain, as well as Hoechst-stained sections of resin-embedded HeLa cells. Network predictions are quantitatively evaluated against corresponding true fluorescence images based on the Pearson correlation coefficient (PCC, or $\rho$) as well as by assessing human recognition of fluorescence predictions on cell nuclei. We additionally assess the network's robustness by measuring its predictive power on EM datasets acquired with varying imaging parameters. Finally, we explore the potential of correlative and predicted fluorescence signals for use as labels in segmentation experiments.






% \subsection{Things we will show}
% \begin{itemize}[noitemsep]
%     \item Can train a CNN to predict fluorescence based on registered CLEM images as training data
%     \begin{itemize}
%         \item Demonstrate on rat pancreas tissue: cell nuclei and insulin granules (micron scale and sub-diffraction limit)
%         \item Demonstrate on zebrafish: cell nuclei
%         \item Demonstrate on mouse heart tissue: phospholamban labelled with TRITC
%         \item Validate with PCC etc.\ and manual counting (for rat pancreas cell nuclei only)
%     \end{itemize}

%     \item CLEMnet is robust
%     \begin{itemize}
%         \item Predictions can be made on different rats
%         \item Predictions can be made on lower signal images (lower dwell) when trained with noise augmentation
%     \end{itemize}

%     \item CLEMnet predictions can be used for (semi/fully)-automated segmentation
%     \begin{itemize}
%         \item CLEMnet data slightly outperforms CLEM data for segmenting cell nuclei
%         \item Caveat that segmentation falls short of manual segmentation
%     \end{itemize}
% \end{itemize}




% Deep convolutional neural networks (CNN) are capable of inferring complex, non-linear relationships between images. Prior work applying deep learning strategies to EM data has often revolved around segmentation tasks. Competitions such as the IEEE International Symposium on Biomedical Imaging (ISBI) challenge for segmentation of neuronal structures in electron microscopic stacks \cite{arganda2015crowdsourcing} have inspired generations of neural network architecture development such as the U-net \cite{ronneberger2015u} and its 3D counterpart \cite{cciccek20163d}. More recently, a CNN has been employed for for whole cell organelle segmentation in a micron-sized volumetric EM dataset \cite{heinrich2020automatic}. Relatively little attention has been paid to alternative applications of deep learning algorithms for volumetric EM data. \textcite{ounkomol2018label} trained a model to facilitate automatic registration of multichannel fluorescence data to EM array tomography data. % Limited to myelin. [More examples].




% As recognition of organelles and other subcellular structures remains a pivotal obstacle in biological EM, [lots and lots of work] has centered around segmentation and classification of these structures. More recently, these efforts have focused on employing deep learning strategies to infer [descriptive adjective] patterns from EM image data rich in structural information \cite{heinrich2020automatic} [25 references therein]. [only expert-level people would otherwise be capable of discerning].
% %
% Competitions such as the IEEE International Symposium on Biomedical Imaging (ISBI) challenge for segmentation of neuronal structures in electron microscopic stacks \cite{arganda2015crowdsourcing} have inspired generations of neural network architecture development such as the U-net \cite{ronneberger2015u} and its 3D counterpart \cite{cciccek20163d}. More recently, a CNN has been employed for whole cell organelle segmentation in a micron-sized volumetric EM dataset \cite{heinrich2020automatic}.


% %
% [No one(?) is making use of multimodal datasets to assist in recognition and segmentation of EM datasets]. 


